{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Section2_Project_DaconCredit.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmv4ggz1SrKu"
      },
      "source": [
        "!pip install category_encoders\n",
        "!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip \n",
        "!pip install feature-engine\n",
        "!pip install -U imbalanced-learn\n",
        "!pip install pdpbox\n",
        "!pip install shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxNi_4lz9c1c"
      },
      "source": [
        "#from pandas_profiling import ProfileReport\n",
        "#ProfileReport(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiURVthGS5Zj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from feature_engine.imputation import RandomSampleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer,SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Dacon_credit/train.csv',index_col='index')\n",
        "\n",
        "def feature_eng(df):\n",
        "    #gender\n",
        "    df.gender = df.gender.replace('F',0) #여성 0\n",
        "    df.gender = df.gender.replace('M',1) #남성 1\n",
        "\n",
        "    #car\n",
        "    df.car = df.car.replace('N',0)\n",
        "    df.car = df.car.replace('Y',1)\n",
        "\n",
        "    #reality\n",
        "    df.reality = df.reality.replace('N',0)\n",
        "    df.reality = df.reality.replace('Y',1)\n",
        "    \n",
        "    #income:  log_transform\n",
        "    transformer = FunctionTransformer(np.log1p, validate=True)\n",
        "    df.income_total = transformer.transform([df.income_total])[0]\n",
        "    \n",
        "    # to abs\n",
        "    df.DAYS_BIRTH = abs(df.DAYS_BIRTH)\n",
        "    df.DAYS_EMPLOYED = abs(df.DAYS_EMPLOYED)\n",
        "    \n",
        "    # outlier , randomforesst impute\n",
        "    df['DAYS_EMPLOYED'].loc[df['DAYS_EMPLOYED']>300000] = None\n",
        "    rf = RandomForestRegressor()\n",
        "    impute = IterativeImputer(random_state=42, estimator =rf)\n",
        "    reshape = np.array(df['DAYS_EMPLOYED']).reshape(-1,1)\n",
        "    df['DAYS_EMPLOYED'] = impute.fit_transform(reshape)\n",
        "\n",
        "\n",
        "    rs_impute = RandomSampleImputer(random_state=42)\n",
        "    s_impute = SimpleImputer(strategy='most_frequent')\n",
        "    #df['occyp_type'] = rs_impute.fit_transform(df[['occyp_type']])\n",
        "    df['occyp_type'] = s_impute.fit_transform(df[['occyp_type']])\n",
        "\n",
        "\n",
        "    \n",
        "    #df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].fillna(df['DAYS_EMPLOYED'].mean())\n",
        "    \n",
        "    #all ones\n",
        "    df = df.drop(columns= 'FLAG_MOBIL')\n",
        "    \n",
        "    #new feature\n",
        "    df['DAYS_UNEMPLOYED'] = df.DAYS_BIRTH  -  df.DAYS_EMPLOYED\n",
        "    \n",
        "    df['in_out_ratio'] = (df['reality']*100 + df['car']*10 + df['child_num'])/(1+df['DAYS_EMPLOYED']*df['begin_month']*df['income_total']/1000)\n",
        "\n",
        "    #중복 데이터들 어떻게 처리할까..포기!\n",
        "    df['card_num'] = 1\n",
        "    key_columns = df.drop(columns = ['begin_month','card_num']).columns\n",
        "\n",
        "    condition1 = df.duplicated(subset = key_columns,\n",
        "                               keep = False) #2개이상\n",
        "    condition2 = df.loc[condition1].duplicated(subset = key_columns,\n",
        "                                               keep = False)#3개이상\n",
        "    condition3 = df.loc[condition1].loc[condition2].duplicated(subset = key_columns,\n",
        "                                                               keep = False)#4개이상\n",
        "    condition4 = df.loc[condition1].loc[condition2].loc[condition3].duplicated(subset = key_columns,\n",
        "                                                                               keep = False)\n",
        "\n",
        "    index = df['card_num'].loc[(condition1)& ~(condition2)].index \n",
        "    df['card_num'].loc[index]= 2\n",
        "    index = df['card_num'].loc[condition1].loc[(condition2)& ~(condition3)].index\n",
        "    df['card_num'].loc[index]= 3\n",
        "    index = df['card_num'].loc[condition1].loc[condition2].loc[(condition3)&~(condition4)].index\n",
        "    df['card_num'].loc[index]= 4\n",
        "    df = df.drop(columns = 'card_num')\n",
        "    df = df.drop(columns = 'email')\n",
        "\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "#One_Hot\n",
        "#income_type\n",
        "\n",
        "target = 'credit'\n",
        "\n",
        "X = feature_eng(train)\n",
        "y = X[target]\n",
        "X = X.drop(columns = target)\n",
        "\n",
        "X_train,X_val,y_train,y_val = train_test_split(X,y, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb4pY3tV_ejF"
      },
      "source": [
        "X.head().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQLGwh0xKDks"
      },
      "source": [
        "'''\n",
        "from imblearn.over_sampling import RandomOverSampler,SMOTE,ADASYN,SMOTEN\n",
        "from imblearn.under_sampling import TomekLinks,EditedNearestNeighbours,InstanceHardnessThreshold,NeighbourhoodCleaningRule\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "ros = NeighbourhoodCleaningRule()\n",
        "enc = TargetEncoder()\n",
        "Z_train = enc.fit_transform(X_train,y_train)\n",
        "Z_val = enc.transform(X_val,y_val)\n",
        "\n",
        "X_train_o,y_train_o = ros.fit_resample(Z_train,y_train)\n",
        "'''\n",
        "#샘플링 의미가 별로 없었다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfcSrb9vK5Qq"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
        "\n",
        "#baseline\n",
        "\n",
        "baseline = y_train.value_counts(normalize= True)\n",
        "y_pred = [baseline]*len(X_train)\n",
        "y_pred_val = [baseline]*len(X_val)\n",
        "\n",
        "print('훈련 log_loss:', log_loss(y_train,y_pred))\n",
        "print('검증 log_loss:', log_loss(y_val,y_pred_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv1hN7l8Szgy"
      },
      "source": [
        "from xgboost import XGBClassifier,DMatrix\n",
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "#xgboost\n",
        "classes_weights = class_weight.compute_sample_weight(\n",
        "    class_weight='balanced',\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "pipe = make_pipeline(TargetEncoder(),\n",
        "                     XGBClassifier(random_state=42,\n",
        "                                   objective = 'multi:softprob',\n",
        "                                   class_weight = classes_weights,\n",
        "                                   xgbclassifier__colsample_bytree = 0.6,\n",
        "                                   gamma=0.3,\n",
        "                                   max_depth = 9,\n",
        "                                   min_child_weight = 2,\n",
        "                                   reg_alpha = 1,\n",
        "                                   sub_sample = 0.8,\n",
        "                                   learning_rate = 0.1\n",
        "                                   ))\n",
        "\n",
        "#xgboost.DMatrix(..., weight = *weight array for individual weights*)\n",
        "\n",
        "{'xgbclassifier__colsample_bytree': [0.5, 0.6, 0.7],\n",
        "  'xgbclassifier__gamma': [0.2,0.3,0.4],\n",
        "  'xgbclassifier__max_depth': [8,9,10],\n",
        "  'xgbclassifier__min_child_weight': [1,2,3],\n",
        "  'xgbclassifier__reg_alpha': [0.1,1,10],\n",
        "  'xgbclassifier__subsample': [0.7,0.8,0.9]\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "pipe.fit(X_train,y_train)\n",
        "y_pred = pipe.predict_proba(X_train)\n",
        "y_pred_val = pipe.predict_proba(X_val)\n",
        "\n",
        "print('훈련 log_loss:', log_loss(y_train,y_pred))\n",
        "print('검증 log_loss:', log_loss(y_val,y_pred_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSp9vus0iC-b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "clf = pipe.named_steps['xgbclassifier']\n",
        "importanc = clf.feature_importances_\n",
        "columns = X_train.columns\n",
        "\n",
        "plt.barh(columns, importanc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obJhG3kSvPkX"
      },
      "source": [
        "#xgboost random search\n",
        "rsc1_param = {\n",
        "    'xgbclassifier__max_depth':range(3,10),\n",
        "    'xgbclassifier__min_child_weight':range(1,6),\n",
        "    'xgbclassifier__gamma':[i/10.0 for i in range(0,5)],\n",
        "    'xgbclassifier__subsample':[i/10.0 for i in range(6,10)],\n",
        "    'xgbclassifier__colsample_bytree':[i/10.0 for i in range(6,10)],\n",
        "    'xgbclassifier__reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
        "\n",
        "}\n",
        "rsc1 = RandomizedSearchCV(estimator=pipe,\n",
        "                          param_distributions = rsc1_param,\n",
        "                          n_iter = 50,\n",
        "                          scoring = 'neg_log_loss',\n",
        "                          cv = 3,\n",
        "                          random_state= 42)\n",
        "rsc1.fit(X_train,y_train)\n",
        "rsc1.cv_results_, rsc1.best_params_, rsc1.best_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqI_vilGu9ew"
      },
      "source": [
        "#xgboost grid search\n",
        "\n",
        "param_test=  {'xgbclassifier__colsample_bytree': [0.5, 0.6, 0.7],\n",
        "  'xgbclassifier__gamma': [0.2,0.3,0.4],\n",
        "  'xgbclassifier__max_depth': [8,9,10],\n",
        "  'xgbclassifier__min_child_weight': [1,2,3],\n",
        "  'xgbclassifier__reg_alpha': [0.1,1,10],\n",
        "  'xgbclassifier__subsample': [0.7,0.8,0.9]\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "xgb_grid = GridSearchCV(estimator= pipe,\n",
        "                        param_grid = param_test,\n",
        "                        scoring='neg_log_loss', n_jobs=-1, cv=5)\n",
        "xgb_grid.fit(X_train,y_train)\n",
        "xgb_grid.cv_results_, xgb_grid.best_params_, xgb_grid.best_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHKEnNNujPy2"
      },
      "source": [
        " {'randomforestclassifier__bootstrap': False,\n",
        "  'randomforestclassifier__max_depth': 40,\n",
        "  'randomforestclassifier__max_features': 'auto',\n",
        "  'randomforestclassifier__min_samples_leaf': 4,\n",
        "  'randomforestclassifier__min_samples_split': 10,\n",
        "  'randomforestclassifier__n_estimators': 400},"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTbI54LuTUlO"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#RandomForest\n",
        "pipe2 = make_pipeline(TargetEncoder(),\n",
        "                      RandomForestClassifier(random_state=15,\n",
        "                                             bootstrap = False,\n",
        "                                             max_depth = 40,\n",
        "                                             max_features = 'auto',\n",
        "                                             min_samples_leaf = 4,\n",
        "                                             min_samples_split = 10,\n",
        "                                             n_estimators = 400\n",
        "                                             ))\n",
        "pipe2.fit(X_train,y_train)\n",
        "y_pred = pipe2.predict_proba(X_train)\n",
        "y_pred_val = pipe2.predict_proba(X_val)\n",
        "\n",
        "print('훈련 log_loss:', log_loss(y_train,y_pred))\n",
        "print('검증 log_loss:', log_loss(y_val,y_pred_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2JyPDarD5M-"
      },
      "source": [
        "#random search\n",
        "\n",
        "random_param ={\n",
        "    'randomforestclassifier__bootstrap': [True, False],\n",
        "    'randomforestclassifier__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
        "    'randomforestclassifier__max_features': ['auto', 'sqrt'],\n",
        "    'randomforestclassifier__min_samples_leaf': [1, 2, 4],\n",
        "    'randomforestclassifier__min_samples_split': [2, 5, 10],\n",
        "    'randomforestclassifier__n_estimators': [200, 400]\n",
        "    }\n",
        "\n",
        "rsc = RandomizedSearchCV(pipe2,\n",
        "                         param_distributions = random_param,\n",
        "                         n_iter = 50,\n",
        "                         scoring = 'neg_log_loss',\n",
        "                         cv = 4,\n",
        "                         random_state = 42)\n",
        "\n",
        "rsc.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhjOoNzGGtuc"
      },
      "source": [
        "rsc.cv_results_, rsc.best_params_, rsc.best_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRcnaEXknZ3R"
      },
      "source": [
        "clf = pipe2.named_steps['randomforestclassifier']\n",
        "importanc = clf.feature_importances_\n",
        "columns = X_train.columns\n",
        "plt.barh(columns, importanc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOZhdPPGSNOq"
      },
      "source": [
        "#dacon 제출용\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Dacon_credit/test.csv',index_col= 'index')\n",
        "X_test = feature_eng(test)\n",
        "pipe.fit(X,y)\n",
        "y_pred_test = pipe2.predict_proba(X_test)\n",
        "submission = pd.DataFrame(y_pred_test)\n",
        "\n",
        "index = pd.DataFrame(X_test.index)\n",
        "submission = pd.concat([index,submission], axis =1)\n",
        "submission.columns = ['index',0,1,2]\n",
        "submission.to_csv('submission.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR6ntORGGRt7"
      },
      "source": [
        "###시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KajHKbSsGRCR"
      },
      "source": [
        "from pdpbox.pdp import pdp_isolate, pdp_plot\n",
        "\n",
        "\n",
        "encoder = TargetEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train,y_train) # 학습데이터\n",
        "X_val_encoded = encoder.transform(X_val,y_val) # 검증데이터"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5CWDRqpHu-i"
      },
      "source": [
        "rf = pipe2.named_steps['randomforestclassifier']\n",
        "\n",
        "feature = 'begin_month'\n",
        "isolated = pdp_isolate(\n",
        "    model=rf, \n",
        "    dataset=X_val_encoded, \n",
        "    model_features=X_val_encoded.columns, \n",
        "    feature=feature,\n",
        "    num_grid_points = 50\n",
        ")\n",
        "\n",
        "pdp_plot(isolated, feature_name=feature);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgNFaE-0JqFA"
      },
      "source": [
        "feature = 'income_total'\n",
        "\n",
        "isolated = pdp_isolate(\n",
        "    model=rf, \n",
        "    dataset=X_val_encoded, \n",
        "    model_features=X_val_encoded.columns, \n",
        "    feature=feature,\n",
        "    num_grid_points = 100\n",
        ")\n",
        "\n",
        "pdp_plot(isolated, \n",
        "         feature_name=feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hTq864MKZ4y"
      },
      "source": [
        "feature = 'DAYS_BIRTH'\n",
        "\n",
        "isolated = pdp_isolate(\n",
        "    model=rf, \n",
        "    dataset=X_val_encoded, \n",
        "    model_features=X_val_encoded.columns, \n",
        "    feature=feature,\n",
        "    num_grid_points = 50\n",
        ")\n",
        "\n",
        "pdp_plot(isolated, feature_name=feature);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDesXICWKZya"
      },
      "source": [
        "import shap\n",
        "\n",
        "row = X_val_encoded.iloc[2]\n",
        "\n",
        "explainer = shap.TreeExplainer(rf)\n",
        "shap_values = explainer.shap_values(row)\n",
        "\n",
        "shap.initjs()\n",
        "shap.force_plot(\n",
        "    base_value=explainer.expected_value[2], \n",
        "    shap_values=shap_values[2],\n",
        "    features=row\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRHghRGKNP0N"
      },
      "source": [
        "shap.initjs()\n",
        "shap_values = explainer.shap_values(X_val_encoded.iloc[:50])\n",
        "shap.force_plot(explainer.expected_value[0], shap_values[0], X_val_encoded.iloc[:50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml0OdpGkRgwf"
      },
      "source": [
        "21000/365\n",
        "\n",
        "begin month 초반에는 좋은 신용도를 보여주는데 처음에는 처음이다보니 잘 상환해야겠다는 마음이 들지만 이후부터는 느슨해지면서 크게 영향을 받지 않는다.(사바사다)\n",
        "total income 일정 수준 이상의 수입에서는 높은 신용도에 긍정적인 영향을 준다.\n",
        "child_num 많을 수록 신용도가 떨어지는데 아마 예상치 못한 지출이 늘어나는 경향이 있는 것이 아닐까라는 생각이 든다\n",
        "family size 마찬가지로 자녀 숫자의 영향으로 그런것이 아닌가 생각됨\n",
        "car 자동차가 있는 경우 생각보다 긍정적인 영향을 주었다. 일시불로 사지 않을 가능성이 크므로 차량 소유 여부가 부정적인 영향을 끼칠수 있다고 생각했는데, 그런 경우도 간혹 있지만\n",
        "대부분 차량 관련 상환은 충실히 한다는 생각을 해볼 수 있지 않을까? 추가적인 조사가 필요하다. \n",
        "\n",
        "남성이 여성보다 긍정적인 영향이 있지만 큰 차이는 아님(여성도 무조건 +)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-niJ4LqOfB4"
      },
      "source": [
        "shap.initjs()\n",
        "shap_values = explainer.shap_values(X_val_encoded.iloc[:50])\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1], X_val_encoded.iloc[:50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-5n_kXAOfvb"
      },
      "source": [
        "shap.initjs()\n",
        "shap_values = explainer.shap_values(X_val_encoded.iloc[:50])\n",
        "shap.force_plot(explainer.expected_value[2], shap_values[2], X_val_encoded.iloc[:50])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}